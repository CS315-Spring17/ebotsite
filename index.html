<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>EthicsBot - A research project at Wellesley College</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="style.css">
</head>
<body>

    <header>
        <div class="container">
            <h1>EthicsBot</h1>
            <nav>
                <a href="#papers">Papers</a>
                <a href="#team">Team</a>
                <a href="#contact">Contact</a>
            </nav>
        </div>
    </header>

    <main>
        <section id="blurb" class="intro-blurb">
            <div class="container">
                <p>
            We present 
            <b style="color: #FF6B6B;">EthicsBot</b>, an innovative, open-source large language model 
            (<b style="color: #FF6B6B;">LLM</b>) project that is being itereatively designed and developed at <a href="https://wellesley.edu" target="_blank" style="color: #FF6B6B; font-weight: bold;">Wellesley College</a> to provide 
            <i style="color: #444444;">real-time, context-aware ethical guidance</i> for researchers. Our work addresses the critical need for timely and accessible ethical support in modern research, particularly when confronting complex digital data on the social web. By investigating the potential of LLMs to serve as research ethics support tools, our goal is to foster deeper ethical reflection that effectively 
            <em style="color: #FF6B6B;">complements</em>, rather than merely complies with, formal institutional review board (IRB) processes.        </p>
            </div>
        </section>

        <section id="papers">
            <div class="container">
                <h2>Papers</h2>
                <div class="paper-grid">
                    
                    <div class="paper-card">
                        <h3><a href="papers/ieee_ethics2025.pdf" target="_blank">EthicsBot: Fine-Tuning Open-Source LLMs to Assist Scientific Investigators in Analyzing Ethical Issues in Research</a></h3>
                        <p class="authors">Spencer Phillips Hey, Charles Weijer, Julie Walsh, Eni Mustafaraj</p>
                        <p class="meta">
                            <strong>Venue:</strong> IEEE International Symposium on Ethics in Engineering, Science, and Technology (ETHICS), Chicago (USA)<br>
                            <strong>Year:</strong> 2025
                        </p>
                        <div class="abstract">
                            <h4>Abstract</h4>
                            <p> Ethical considerations are fundamental to responsible research, yet many investigators struggle to identify and analyze ethical concerns in their study designs. Institutional review boards (IRBs) and other regulatory bodies, while essential, are often perceived as bureaucratic obstacles rather than collaborative partners in ethical inquiry. Recent advances in large language models (LLMs) offer an opportunity to enhance the way researchers engage with ethical analysis. This paper introduces EthicsBot, an innovative project that proposes to leverage open-source LLMs to provide real-time, context-aware ethical guidance for researchers. <a href="papers/ieee_ethics2025.pdf" target="_blank">Download PDF</a></p>
                        </div>
                    </div>

                    <div class="paper-card">
                        <h3><a href="papers/aaai_aies2025.pdf" target="_blank">Comparing Human and LLM Ethical Analyses: A Case Study in Computational
Social Science Research</a></h3>
                        <p class="authors">Spencer Phillips Hey, Julie Walsh, Eni Mustafaraj</p>
                        <p class="meta">
                            <strong>Venue:</strong> The 8th AAAI/ACM Conference on AI, Ethics, and Society (AIES), Madrid (Spain)<br>
                            <strong>Year:</strong> 2025
                        </p>
                        <div class="abstract">
                            <h4>Abstract</h4>
                            <p>As researchers increasingly engage with ethically complex
digital phenomena, timely and accessible support for ethical reflection is essentialâ€”yet often unavailable beyond formal institutional review processes, which are more focused
on regulatory compliance than ethics. This paper investigates the potential of large language models (LLMs) to serve as re-
search ethics support tools by providing immediate, context-sensitive feedback on draft research protocols. We analyze a draft research proposing to scrape digital platforms for data
on "Sephora Kids" (a trend in which minors promote beauty products on platforms like YouTube and TikTok) as a case study to explore this possibility. Two human ethicists and
two LLMs (GPT-4o and Claude 3.7 Sonnet) independently reviewed the proposal and produced ethical evaluations. We then compared the outputs to assess whether LLMs could
meaningfully assist researchers in identifying and engaging with ethical issues. Our findings suggest that LLMs can already offer valuable support. <a href="papers/aaai_aies2025.pdf" target="_blank">Download PDF</a></p>
                        </div>
                    </div>

                </div>
            </div>
        </section>

        <section id="team" class="team-section">
            <div class="container">
                <h2>Our Team</h2>
                <div class="team-photo-placeholder">
                    <img src="ethicsbot-team.jpg" alt="Photo of the entire research team" class="team-group-photo">
                    <p class="caption">The core research group at the Wellesley College Science Center Summer Research Poster Session (July 2025).</p>
                </div>

                <div class="team-members">

                    <div class="member-bio">
                        <h3>Dr. Eni Mustafaraj</h3>
                        <p class="affiliation"><strong>Affiliation:</strong> Wellesley College</p>
                        <p>Dr. Mustafaraj is an Associate Professor of Computer Science at Wellesley College. She is the PI of the NSF grant "Pathways to Ethics of Technology in the Liberal Arts Curriculum" that supports this research.</p>
                    </div>

                    <div class="member-bio">
                        <h3>Dr. Julie Walsh</h3>
                        <p class="affiliation"><strong>Affiliation:</strong> Wellesley College</p>
                        <p>Dr. Walsh is the Whitehead Associate Professor of Critical Thought and Associate Professor of Philosophy at Wellesley College. She is the co-PI of the NSF grant "Pathways to Ethics of Technology in the Liberal Arts Curriculum" that supports this research.</p>
                    </div>


                    <div class="member-bio">
                        <h3>Dr. Spencer Philips Hey</h3>
                        <p class="affiliation"><strong>Affiliation: </strong>Hey Research & Innovation</p>
                        <p>Dr. Hey is a the founder of Hey Research & Innovation. He has deep research expertise on the ethics of human subjects research. His publications can be found <a href="https://scholar.google.com/citations?user=tgUQIQYAAAAJ&hl=en">here</a>.</p>
                    </div>
                    

                    <div class="member-bio">
                        <h3>Crystal Zhao</h3>
                        <p class="affiliation"><strong>Affiliation:</strong> Wellesley College</p>
                        <p>Crystal is an undergraduate student at Wellesley College studying Data Science and Peace & Justice.</p>
                    </div>

                    <div class="member-bio">
                        <h3>Jessica Chen</h3>
                        <p class="affiliation"><strong>Affiliation:</strong> Wellesley College</p>
                        <p>Jessica an undergraduate student at Wellesley College studying Computer Science and Political Science.</p>
                    </div>

                </div>

            </div>
        </section>

        <section id="contact" class="contact-section">
            <div class="container">
                <h2>Contact Us</h2>
                <p>For research inquiries, collaborations, or questions about the papers, please contact us at: <span id="info"></span>.</p>

            </div>
        </section>
    </main>

    <section class="funding-section">
    <div class="container funding-acknowledgment">
        <h2>Funding Acknowledgment</h2>
        <div class="funding-content">
            <div class="logo-container">
                <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2220772" target="_blank" aria-label="View NSF Project Page">
                    <img src="nsf-logo.png" alt="National Science Foundation Logo" class="nsf-logo">
                </a>
            </div>
            <p class="acknowledgment-text">
                This research is generously supported by the 
                <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2220772" target="_blank" style="color: #FF6B6B; font-weight: bold;">National Science Foundation (NSF)</a>
                under Grant No. 2220772. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.
            </p>
        </div>
    </div>
</section>

    <footer>
        <div class="container">
            <p>&copy; 2025 EthicsBot. All rights reserved.</p>
        </div>
    </footer>

<script>
    const u = 'ethics-bot'; // 
    const d = 'wellesley.edu'; 
    // ------------------------------

    const fe = u + '@' + d;
    const eee = document.getElementById('info');

    if (eee) {
        const mtl = document.createElement('a');
        mtl.href = 'mailto:' + fe;
        mtl.textContent = fe;
        eee.appendChild(mtl);
    }
</script>

</body>
</html>